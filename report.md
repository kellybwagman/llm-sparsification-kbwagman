# Lab 4 Report

I use PyTorch to investigate sparsity in 3 models (GPT-2, BERT, T5). First, I do an analysis of the parameters meaningfully larger than 0. After looking at the data, I chose a cutoff point of 0.1 and count the percent of parameters above this cutoff, both overall and by layer (see below and in png charts). I then use the built-in pruning offered by PyTorch to prune 10%, 50%, 90%, 95%, and 99% of the smallest parameters. From my analysis, I think sparsification is challenging because the number of 'big' parameters changes signficantly by layer and it not clear which to prune at the outset. I also noticed a long tail, where just a handful of parameters were larger than 2 (some even close to 10) although most 'big' values hover around 1.

# GPT-2
What fraction of parameters >> 0 overall? Percent of model parameters > 0.1 is 70.64% (also see chart in gpt2_histogram.png)
What fraction of parameters >> 0 by layer? See table:
+-------------------------+----------------------+
|          Layers         | Percent Params > 0.1 |
+-------------------------+----------------------+
|        wte.weight       |        73.68%        |
|        wpe.weight       |        53.51%        |
|     h.0.ln_1.weight     |        91.41%        |
|      h.0.ln_1.bias      |        73.05%        |
|  h.0.attn.c_attn.weight |        71.91%        |
|   h.0.attn.c_attn.bias  |        68.4%         |
|  h.0.attn.c_proj.weight |        60.05%        |
|   h.0.attn.c_proj.bias  |        63.67%        |
|     h.0.ln_2.weight     |        96.88%        |
|      h.0.ln_2.bias      |        48.44%        |
|   h.0.mlp.c_fc.weight   |        70.45%        |
|    h.0.mlp.c_fc.bias    |        80.76%        |
|  h.0.mlp.c_proj.weight  |        60.34%        |
|   h.0.mlp.c_proj.bias   |        56.12%        |
|     h.1.ln_1.weight     |        99.61%        |
|      h.1.ln_1.bias      |        76.95%        |
|  h.1.attn.c_attn.weight |        68.71%        |
|   h.1.attn.c_attn.bias  |        65.32%        |
|  h.1.attn.c_proj.weight |        61.19%        |
|   h.1.attn.c_proj.bias  |        60.29%        |
|     h.1.ln_2.weight     |        99.74%        |
|      h.1.ln_2.bias      |        60.94%        |
|   h.1.mlp.c_fc.weight   |        70.05%        |
|    h.1.mlp.c_fc.bias    |        78.26%        |
|  h.1.mlp.c_proj.weight  |        60.49%        |
|   h.1.mlp.c_proj.bias   |        60.16%        |
|     h.2.ln_1.weight     |        99.48%        |
|      h.2.ln_1.bias      |        59.64%        |
|  h.2.attn.c_attn.weight |        71.13%        |
|   h.2.attn.c_attn.bias  |        65.49%        |
|  h.2.attn.c_proj.weight |        59.14%        |
|   h.2.attn.c_proj.bias  |        71.48%        |
|     h.2.ln_2.weight     |        98.7%         |
|      h.2.ln_2.bias      |        41.54%        |
|   h.2.mlp.c_fc.weight   |        71.39%        |
|    h.2.mlp.c_fc.bias    |        85.25%        |
|  h.2.mlp.c_proj.weight  |        62.1%         |
|   h.2.mlp.c_proj.bias   |        65.62%        |
|     h.3.ln_1.weight     |        98.83%        |
|      h.3.ln_1.bias      |        29.3%         |
|  h.3.attn.c_attn.weight |        71.86%        |
|   h.3.attn.c_attn.bias  |        65.41%        |
|  h.3.attn.c_proj.weight |        60.32%        |
|   h.3.attn.c_proj.bias  |        64.97%        |
|     h.3.ln_2.weight     |        98.83%        |
|      h.3.ln_2.bias      |        35.81%        |
|   h.3.mlp.c_fc.weight   |        71.67%        |
|    h.3.mlp.c_fc.bias    |        87.89%        |
|  h.3.mlp.c_proj.weight  |        61.9%         |
|   h.3.mlp.c_proj.bias   |        65.23%        |
|     h.4.ln_1.weight     |        99.61%        |
|      h.4.ln_1.bias      |        19.92%        |
|  h.4.attn.c_attn.weight |        71.99%        |
|   h.4.attn.c_attn.bias  |        65.15%        |
|  h.4.attn.c_proj.weight |        62.5%         |
|   h.4.attn.c_proj.bias  |        63.54%        |
|     h.4.ln_2.weight     |        99.48%        |
|      h.4.ln_2.bias      |        48.18%        |
|   h.4.mlp.c_fc.weight   |        71.27%        |
|    h.4.mlp.c_fc.bias    |        85.48%        |
|  h.4.mlp.c_proj.weight  |        62.17%        |
|   h.4.mlp.c_proj.bias   |        70.7%         |
|     h.5.ln_1.weight     |        99.87%        |
|      h.5.ln_1.bias      |        14.45%        |
|  h.5.attn.c_attn.weight |        70.39%        |
|   h.5.attn.c_attn.bias  |        60.72%        |
|  h.5.attn.c_proj.weight |        63.29%        |
|   h.5.attn.c_proj.bias  |        67.32%        |
|     h.5.ln_2.weight     |        99.35%        |
|      h.5.ln_2.bias      |        36.72%        |
|   h.5.mlp.c_fc.weight   |        70.95%        |
|    h.5.mlp.c_fc.bias    |        85.48%        |
|  h.5.mlp.c_proj.weight  |        63.97%        |
|   h.5.mlp.c_proj.bias   |        64.97%        |
|     h.6.ln_1.weight     |        99.87%        |
|      h.6.ln_1.bias      |        13.02%        |
|  h.6.attn.c_attn.weight |        70.56%        |
|   h.6.attn.c_attn.bias  |        62.59%        |
|  h.6.attn.c_proj.weight |        67.53%        |
|   h.6.attn.c_proj.bias  |        68.88%        |
|     h.6.ln_2.weight     |        99.48%        |
|      h.6.ln_2.bias      |        41.93%        |
|   h.6.mlp.c_fc.weight   |        70.85%        |
|    h.6.mlp.c_fc.bias    |        85.68%        |
|  h.6.mlp.c_proj.weight  |        66.35%        |
|   h.6.mlp.c_proj.bias   |        66.28%        |
|     h.7.ln_1.weight     |        99.74%        |
|      h.7.ln_1.bias      |        9.77%         |
|  h.7.attn.c_attn.weight |        71.14%        |
|   h.7.attn.c_attn.bias  |        63.93%        |
|  h.7.attn.c_proj.weight |        67.49%        |
|   h.7.attn.c_proj.bias  |        76.3%         |
|     h.7.ln_2.weight     |        99.22%        |
|      h.7.ln_2.bias      |        37.11%        |
|   h.7.mlp.c_fc.weight   |        71.28%        |
|    h.7.mlp.c_fc.bias    |        87.14%        |
|  h.7.mlp.c_proj.weight  |        68.88%        |
|   h.7.mlp.c_proj.bias   |        70.05%        |
|     h.8.ln_1.weight     |        99.61%        |
|      h.8.ln_1.bias      |        15.49%        |
|  h.8.attn.c_attn.weight |        71.07%        |
|   h.8.attn.c_attn.bias  |        64.5%         |
|  h.8.attn.c_proj.weight |        69.42%        |
|   h.8.attn.c_proj.bias  |        71.09%        |
|     h.8.ln_2.weight     |        99.22%        |
|      h.8.ln_2.bias      |        49.48%        |
|   h.8.mlp.c_fc.weight   |        71.38%        |
|    h.8.mlp.c_fc.bias    |        86.13%        |
|  h.8.mlp.c_proj.weight  |        71.92%        |
|   h.8.mlp.c_proj.bias   |        66.54%        |
|     h.9.ln_1.weight     |        99.61%        |
|      h.9.ln_1.bias      |        15.62%        |
|  h.9.attn.c_attn.weight |        70.88%        |
|   h.9.attn.c_attn.bias  |        65.32%        |
|  h.9.attn.c_proj.weight |        71.79%        |
|   h.9.attn.c_proj.bias  |        81.77%        |
|     h.9.ln_2.weight     |        99.22%        |
|      h.9.ln_2.bias      |        37.76%        |
|   h.9.mlp.c_fc.weight   |        71.61%        |
|    h.9.mlp.c_fc.bias    |        86.56%        |
|  h.9.mlp.c_proj.weight  |        74.94%        |
|   h.9.mlp.c_proj.bias   |        73.18%        |
|     h.10.ln_1.weight    |        99.61%        |
|      h.10.ln_1.bias     |        16.41%        |
| h.10.attn.c_attn.weight |        70.75%        |
|  h.10.attn.c_attn.bias  |        66.75%        |
| h.10.attn.c_proj.weight |        72.79%        |
|  h.10.attn.c_proj.bias  |        74.48%        |
|     h.10.ln_2.weight    |        99.22%        |
|      h.10.ln_2.bias     |        14.06%        |
|   h.10.mlp.c_fc.weight  |        71.6%         |
|    h.10.mlp.c_fc.bias   |        84.73%        |
|  h.10.mlp.c_proj.weight |        77.46%        |
|   h.10.mlp.c_proj.bias  |        79.17%        |
|     h.11.ln_1.weight    |        100.0%        |
|      h.11.ln_1.bias     |        19.27%        |
| h.11.attn.c_attn.weight |        70.22%        |
|  h.11.attn.c_attn.bias  |        63.02%        |
| h.11.attn.c_proj.weight |        73.45%        |
|  h.11.attn.c_proj.bias  |        77.21%        |
|     h.11.ln_2.weight    |        98.7%         |
|      h.11.ln_2.bias     |        36.59%        |
|   h.11.mlp.c_fc.weight  |        71.82%        |
|    h.11.mlp.c_fc.bias   |        83.43%        |
|  h.11.mlp.c_proj.weight |        79.0%         |
|   h.11.mlp.c_proj.bias  |        67.45%        |
|       ln_f.weight       |        98.96%        |
|        ln_f.bias        |        65.76%        |
+-------------------------+----------------------+

# BERT
What fraction of parameters >> 0 overall? Percent of model parameters > 0.1 is 55.6% (also see chart in bert_histogram.png)
What fraction of parameters >> 0 by layer? See table:
+----------------------------------------------------------------------+----------------------+
|                                Layers                                | Percent Params > 0.1 |
+----------------------------------------------------------------------+----------------------+
|              encoder.embeddings.word_embeddings.weight               |        77.06%        |
|            encoder.embeddings.position_embeddings.weight             |        50.13%        |
|           encoder.embeddings.token_type_embeddings.weight            |        48.5%         |
|                 encoder.embeddings.LayerNorm.weight                  |        99.87%        |
|                  encoder.embeddings.LayerNorm.bias                   |        75.39%        |
|         encoder.encoder.layer.0.attention.self.query.weight          |        51.22%        |
|          encoder.encoder.layer.0.attention.self.query.bias           |        85.29%        |
|          encoder.encoder.layer.0.attention.self.key.weight           |        51.17%        |
|           encoder.encoder.layer.0.attention.self.key.bias            |        52.73%        |
|         encoder.encoder.layer.0.attention.self.value.weight          |        50.11%        |
|          encoder.encoder.layer.0.attention.self.value.bias           |        49.35%        |
|        encoder.encoder.layer.0.attention.output.dense.weight         |        50.26%        |
|         encoder.encoder.layer.0.attention.output.dense.bias          |        49.87%        |
|      encoder.encoder.layer.0.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.0.attention.output.LayerNorm.bias        |        80.08%        |
|          encoder.encoder.layer.0.intermediate.dense.weight           |        50.57%        |
|           encoder.encoder.layer.0.intermediate.dense.bias            |        99.06%        |
|             encoder.encoder.layer.0.output.dense.weight              |        50.55%        |
|              encoder.encoder.layer.0.output.dense.bias               |        55.99%        |
|           encoder.encoder.layer.0.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.0.output.LayerNorm.bias             |        72.92%        |
|         encoder.encoder.layer.1.attention.self.query.weight          |        51.37%        |
|          encoder.encoder.layer.1.attention.self.query.bias           |        68.49%        |
|          encoder.encoder.layer.1.attention.self.key.weight           |        51.01%        |
|           encoder.encoder.layer.1.attention.self.key.bias            |        47.92%        |
|         encoder.encoder.layer.1.attention.self.value.weight          |        50.04%        |
|          encoder.encoder.layer.1.attention.self.value.bias           |        51.04%        |
|        encoder.encoder.layer.1.attention.output.dense.weight         |        50.16%        |
|         encoder.encoder.layer.1.attention.output.dense.bias          |        50.0%         |
|      encoder.encoder.layer.1.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.1.attention.output.LayerNorm.bias        |        72.79%        |
|          encoder.encoder.layer.1.intermediate.dense.weight           |        50.68%        |
|           encoder.encoder.layer.1.intermediate.dense.bias            |        97.07%        |
|             encoder.encoder.layer.1.output.dense.weight              |        50.62%        |
|              encoder.encoder.layer.1.output.dense.bias               |        56.64%        |
|           encoder.encoder.layer.1.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.1.output.LayerNorm.bias             |        75.91%        |
|         encoder.encoder.layer.2.attention.self.query.weight          |        51.9%         |
|          encoder.encoder.layer.2.attention.self.query.bias           |        68.36%        |
|          encoder.encoder.layer.2.attention.self.key.weight           |        51.71%        |
|           encoder.encoder.layer.2.attention.self.key.bias            |        49.09%        |
|         encoder.encoder.layer.2.attention.self.value.weight          |        50.16%        |
|          encoder.encoder.layer.2.attention.self.value.bias           |        53.39%        |
|        encoder.encoder.layer.2.attention.output.dense.weight         |        50.1%         |
|         encoder.encoder.layer.2.attention.output.dense.bias          |        61.59%        |
|      encoder.encoder.layer.2.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.2.attention.output.LayerNorm.bias        |        75.65%        |
|          encoder.encoder.layer.2.intermediate.dense.weight           |        50.77%        |
|           encoder.encoder.layer.2.intermediate.dense.bias            |        97.04%        |
|             encoder.encoder.layer.2.output.dense.weight              |        50.68%        |
|              encoder.encoder.layer.2.output.dense.bias               |        56.51%        |
|           encoder.encoder.layer.2.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.2.output.LayerNorm.bias             |        70.96%        |
|         encoder.encoder.layer.3.attention.self.query.weight          |        50.78%        |
|          encoder.encoder.layer.3.attention.self.query.bias           |        63.93%        |
|          encoder.encoder.layer.3.attention.self.key.weight           |        51.08%        |
|           encoder.encoder.layer.3.attention.self.key.bias            |        53.12%        |
|         encoder.encoder.layer.3.attention.self.value.weight          |        50.28%        |
|          encoder.encoder.layer.3.attention.self.value.bias           |        49.87%        |
|        encoder.encoder.layer.3.attention.output.dense.weight         |        50.11%        |
|         encoder.encoder.layer.3.attention.output.dense.bias          |        56.77%        |
|      encoder.encoder.layer.3.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.3.attention.output.LayerNorm.bias        |        74.74%        |
|          encoder.encoder.layer.3.intermediate.dense.weight           |        50.97%        |
|           encoder.encoder.layer.3.intermediate.dense.bias            |        95.67%        |
|             encoder.encoder.layer.3.output.dense.weight              |        50.7%         |
|              encoder.encoder.layer.3.output.dense.bias               |        54.04%        |
|           encoder.encoder.layer.3.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.3.output.LayerNorm.bias             |        76.17%        |
|         encoder.encoder.layer.4.attention.self.query.weight          |        51.01%        |
|          encoder.encoder.layer.4.attention.self.query.bias           |        69.27%        |
|          encoder.encoder.layer.4.attention.self.key.weight           |        50.9%         |
|           encoder.encoder.layer.4.attention.self.key.bias            |        48.83%        |
|         encoder.encoder.layer.4.attention.self.value.weight          |        50.33%        |
|          encoder.encoder.layer.4.attention.self.value.bias           |        50.91%        |
|        encoder.encoder.layer.4.attention.output.dense.weight         |        50.23%        |
|         encoder.encoder.layer.4.attention.output.dense.bias          |        52.34%        |
|      encoder.encoder.layer.4.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.4.attention.output.LayerNorm.bias        |        70.57%        |
|          encoder.encoder.layer.4.intermediate.dense.weight           |        50.92%        |
|           encoder.encoder.layer.4.intermediate.dense.bias            |        96.09%        |
|             encoder.encoder.layer.4.output.dense.weight              |        50.84%        |
|              encoder.encoder.layer.4.output.dense.bias               |        51.17%        |
|           encoder.encoder.layer.4.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.4.output.LayerNorm.bias             |        75.78%        |
|         encoder.encoder.layer.5.attention.self.query.weight          |        51.17%        |
|          encoder.encoder.layer.5.attention.self.query.bias           |        64.32%        |
|          encoder.encoder.layer.5.attention.self.key.weight           |        51.28%        |
|           encoder.encoder.layer.5.attention.self.key.bias            |        49.09%        |
|         encoder.encoder.layer.5.attention.self.value.weight          |        50.31%        |
|          encoder.encoder.layer.5.attention.self.value.bias           |        47.92%        |
|        encoder.encoder.layer.5.attention.output.dense.weight         |        50.28%        |
|         encoder.encoder.layer.5.attention.output.dense.bias          |        50.52%        |
|      encoder.encoder.layer.5.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.5.attention.output.LayerNorm.bias        |        71.35%        |
|          encoder.encoder.layer.5.intermediate.dense.weight           |        50.88%        |
|           encoder.encoder.layer.5.intermediate.dense.bias            |        95.31%        |
|             encoder.encoder.layer.5.output.dense.weight              |        50.81%        |
|              encoder.encoder.layer.5.output.dense.bias               |        51.04%        |
|           encoder.encoder.layer.5.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.5.output.LayerNorm.bias             |        72.66%        |
|         encoder.encoder.layer.6.attention.self.query.weight          |        51.02%        |
|          encoder.encoder.layer.6.attention.self.query.bias           |        66.02%        |
|          encoder.encoder.layer.6.attention.self.key.weight           |        51.03%        |
|           encoder.encoder.layer.6.attention.self.key.bias            |        51.56%        |
|         encoder.encoder.layer.6.attention.self.value.weight          |        50.28%        |
|          encoder.encoder.layer.6.attention.self.value.bias           |        50.0%         |
|        encoder.encoder.layer.6.attention.output.dense.weight         |        50.24%        |
|         encoder.encoder.layer.6.attention.output.dense.bias          |        51.69%        |
|      encoder.encoder.layer.6.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.6.attention.output.LayerNorm.bias        |        68.62%        |
|          encoder.encoder.layer.6.intermediate.dense.weight           |        50.88%        |
|           encoder.encoder.layer.6.intermediate.dense.bias            |        95.08%        |
|             encoder.encoder.layer.6.output.dense.weight              |        50.68%        |
|              encoder.encoder.layer.6.output.dense.bias               |        55.73%        |
|           encoder.encoder.layer.6.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.6.output.LayerNorm.bias             |        74.35%        |
|         encoder.encoder.layer.7.attention.self.query.weight          |        51.05%        |
|          encoder.encoder.layer.7.attention.self.query.bias           |        65.36%        |
|          encoder.encoder.layer.7.attention.self.key.weight           |        51.17%        |
|           encoder.encoder.layer.7.attention.self.key.bias            |        49.35%        |
|         encoder.encoder.layer.7.attention.self.value.weight          |        50.06%        |
|          encoder.encoder.layer.7.attention.self.value.bias           |        52.34%        |
|        encoder.encoder.layer.7.attention.output.dense.weight         |        50.2%         |
|         encoder.encoder.layer.7.attention.output.dense.bias          |        51.95%        |
|      encoder.encoder.layer.7.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.7.attention.output.LayerNorm.bias        |        73.44%        |
|          encoder.encoder.layer.7.intermediate.dense.weight           |        50.35%        |
|           encoder.encoder.layer.7.intermediate.dense.bias            |        96.61%        |
|             encoder.encoder.layer.7.output.dense.weight              |        50.55%        |
|              encoder.encoder.layer.7.output.dense.bias               |        58.72%        |
|           encoder.encoder.layer.7.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.7.output.LayerNorm.bias             |        75.0%         |
|         encoder.encoder.layer.8.attention.self.query.weight          |        51.16%        |
|          encoder.encoder.layer.8.attention.self.query.bias           |        71.61%        |
|          encoder.encoder.layer.8.attention.self.key.weight           |        51.34%        |
|           encoder.encoder.layer.8.attention.self.key.bias            |        48.18%        |
|         encoder.encoder.layer.8.attention.self.value.weight          |        50.34%        |
|          encoder.encoder.layer.8.attention.self.value.bias           |        54.17%        |
|        encoder.encoder.layer.8.attention.output.dense.weight         |        50.24%        |
|         encoder.encoder.layer.8.attention.output.dense.bias          |        50.26%        |
|      encoder.encoder.layer.8.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.8.attention.output.LayerNorm.bias        |        74.35%        |
|          encoder.encoder.layer.8.intermediate.dense.weight           |        50.25%        |
|           encoder.encoder.layer.8.intermediate.dense.bias            |        97.4%         |
|             encoder.encoder.layer.8.output.dense.weight              |        50.46%        |
|              encoder.encoder.layer.8.output.dense.bias               |        59.24%        |
|           encoder.encoder.layer.8.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.8.output.LayerNorm.bias             |        75.52%        |
|         encoder.encoder.layer.9.attention.self.query.weight          |        51.58%        |
|          encoder.encoder.layer.9.attention.self.query.bias           |        73.96%        |
|          encoder.encoder.layer.9.attention.self.key.weight           |        51.43%        |
|           encoder.encoder.layer.9.attention.self.key.bias            |        48.44%        |
|         encoder.encoder.layer.9.attention.self.value.weight          |        50.13%        |
|          encoder.encoder.layer.9.attention.self.value.bias           |        51.69%        |
|        encoder.encoder.layer.9.attention.output.dense.weight         |        50.22%        |
|         encoder.encoder.layer.9.attention.output.dense.bias          |        54.04%        |
|      encoder.encoder.layer.9.attention.output.LayerNorm.weight       |        100.0%        |
|       encoder.encoder.layer.9.attention.output.LayerNorm.bias        |        73.7%         |
|          encoder.encoder.layer.9.intermediate.dense.weight           |        50.16%        |
|           encoder.encoder.layer.9.intermediate.dense.bias            |        98.27%        |
|             encoder.encoder.layer.9.output.dense.weight              |        50.56%        |
|              encoder.encoder.layer.9.output.dense.bias               |        59.11%        |
|           encoder.encoder.layer.9.output.LayerNorm.weight            |        100.0%        |
|            encoder.encoder.layer.9.output.LayerNorm.bias             |        76.04%        |
|         encoder.encoder.layer.10.attention.self.query.weight         |        51.4%         |
|          encoder.encoder.layer.10.attention.self.query.bias          |        69.14%        |
|          encoder.encoder.layer.10.attention.self.key.weight          |        51.39%        |
|           encoder.encoder.layer.10.attention.self.key.bias           |        49.35%        |
|         encoder.encoder.layer.10.attention.self.value.weight         |        50.45%        |
|          encoder.encoder.layer.10.attention.self.value.bias          |        50.91%        |
|        encoder.encoder.layer.10.attention.output.dense.weight        |        50.17%        |
|         encoder.encoder.layer.10.attention.output.dense.bias         |        54.56%        |
|      encoder.encoder.layer.10.attention.output.LayerNorm.weight      |        100.0%        |
|       encoder.encoder.layer.10.attention.output.LayerNorm.bias       |        66.02%        |
|          encoder.encoder.layer.10.intermediate.dense.weight          |        50.47%        |
|           encoder.encoder.layer.10.intermediate.dense.bias           |        99.06%        |
|             encoder.encoder.layer.10.output.dense.weight             |        50.4%         |
|              encoder.encoder.layer.10.output.dense.bias              |        65.23%        |
|           encoder.encoder.layer.10.output.LayerNorm.weight           |        100.0%        |
|            encoder.encoder.layer.10.output.LayerNorm.bias            |        85.94%        |
|         encoder.encoder.layer.11.attention.self.query.weight         |        51.49%        |
|          encoder.encoder.layer.11.attention.self.query.bias          |        79.43%        |
|          encoder.encoder.layer.11.attention.self.key.weight          |        51.01%        |
|           encoder.encoder.layer.11.attention.self.key.bias           |        51.43%        |
|         encoder.encoder.layer.11.attention.self.value.weight         |        50.66%        |
|          encoder.encoder.layer.11.attention.self.value.bias          |        48.44%        |
|        encoder.encoder.layer.11.attention.output.dense.weight        |        50.37%        |
|         encoder.encoder.layer.11.attention.output.dense.bias         |        50.26%        |
|      encoder.encoder.layer.11.attention.output.LayerNorm.weight      |        100.0%        |
|       encoder.encoder.layer.11.attention.output.LayerNorm.bias       |        72.14%        |
|          encoder.encoder.layer.11.intermediate.dense.weight          |        50.12%        |
|           encoder.encoder.layer.11.intermediate.dense.bias           |        97.33%        |
|             encoder.encoder.layer.11.output.dense.weight             |        50.32%        |
|              encoder.encoder.layer.11.output.dense.bias              |        51.69%        |
|           encoder.encoder.layer.11.output.LayerNorm.weight           |        100.0%        |
|            encoder.encoder.layer.11.output.LayerNorm.bias            |        68.62%        |
|                     encoder.pooler.dense.weight                      |        50.46%        |
|                      encoder.pooler.dense.bias                       |        51.56%        |
|            decoder.bert.embeddings.word_embeddings.weight            |        77.06%        |
|          decoder.bert.embeddings.position_embeddings.weight          |        50.13%        |
|         decoder.bert.embeddings.token_type_embeddings.weight         |        48.5%         |
|               decoder.bert.embeddings.LayerNorm.weight               |        99.87%        |
|                decoder.bert.embeddings.LayerNorm.bias                |        75.39%        |
|       decoder.bert.encoder.layer.0.attention.self.query.weight       |        51.22%        |
|        decoder.bert.encoder.layer.0.attention.self.query.bias        |        85.29%        |
|        decoder.bert.encoder.layer.0.attention.self.key.weight        |        51.17%        |
|         decoder.bert.encoder.layer.0.attention.self.key.bias         |        52.73%        |
|       decoder.bert.encoder.layer.0.attention.self.value.weight       |        50.11%        |
|        decoder.bert.encoder.layer.0.attention.self.value.bias        |        49.35%        |
|      decoder.bert.encoder.layer.0.attention.output.dense.weight      |        50.26%        |
|       decoder.bert.encoder.layer.0.attention.output.dense.bias       |        49.87%        |
|    decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias     |        80.08%        |
|    decoder.bert.encoder.layer.0.crossattention.self.query.weight     |        50.12%        |
|     decoder.bert.encoder.layer.0.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.0.crossattention.self.key.weight      |        50.07%        |
|      decoder.bert.encoder.layer.0.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.0.crossattention.self.value.weight     |        50.03%        |
|     decoder.bert.encoder.layer.0.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.0.crossattention.output.dense.weight    |        50.05%        |
|    decoder.bert.encoder.layer.0.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.0.intermediate.dense.weight        |        50.57%        |
|         decoder.bert.encoder.layer.0.intermediate.dense.bias         |        99.06%        |
|           decoder.bert.encoder.layer.0.output.dense.weight           |        50.55%        |
|            decoder.bert.encoder.layer.0.output.dense.bias            |        55.99%        |
|         decoder.bert.encoder.layer.0.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.0.output.LayerNorm.bias          |        72.92%        |
|       decoder.bert.encoder.layer.1.attention.self.query.weight       |        51.37%        |
|        decoder.bert.encoder.layer.1.attention.self.query.bias        |        68.49%        |
|        decoder.bert.encoder.layer.1.attention.self.key.weight        |        51.01%        |
|         decoder.bert.encoder.layer.1.attention.self.key.bias         |        47.92%        |
|       decoder.bert.encoder.layer.1.attention.self.value.weight       |        50.04%        |
|        decoder.bert.encoder.layer.1.attention.self.value.bias        |        51.04%        |
|      decoder.bert.encoder.layer.1.attention.output.dense.weight      |        50.16%        |
|       decoder.bert.encoder.layer.1.attention.output.dense.bias       |        50.0%         |
|    decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias     |        72.79%        |
|    decoder.bert.encoder.layer.1.crossattention.self.query.weight     |        49.98%        |
|     decoder.bert.encoder.layer.1.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.1.crossattention.self.key.weight      |        50.03%        |
|      decoder.bert.encoder.layer.1.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.1.crossattention.self.value.weight     |        49.96%        |
|     decoder.bert.encoder.layer.1.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.1.crossattention.output.dense.weight    |        50.03%        |
|    decoder.bert.encoder.layer.1.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.1.intermediate.dense.weight        |        50.68%        |
|         decoder.bert.encoder.layer.1.intermediate.dense.bias         |        97.07%        |
|           decoder.bert.encoder.layer.1.output.dense.weight           |        50.62%        |
|            decoder.bert.encoder.layer.1.output.dense.bias            |        56.64%        |
|         decoder.bert.encoder.layer.1.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.1.output.LayerNorm.bias          |        75.91%        |
|       decoder.bert.encoder.layer.2.attention.self.query.weight       |        51.9%         |
|        decoder.bert.encoder.layer.2.attention.self.query.bias        |        68.36%        |
|        decoder.bert.encoder.layer.2.attention.self.key.weight        |        51.71%        |
|         decoder.bert.encoder.layer.2.attention.self.key.bias         |        49.09%        |
|       decoder.bert.encoder.layer.2.attention.self.value.weight       |        50.16%        |
|        decoder.bert.encoder.layer.2.attention.self.value.bias        |        53.39%        |
|      decoder.bert.encoder.layer.2.attention.output.dense.weight      |        50.1%         |
|       decoder.bert.encoder.layer.2.attention.output.dense.bias       |        61.59%        |
|    decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias     |        75.65%        |
|    decoder.bert.encoder.layer.2.crossattention.self.query.weight     |        50.04%        |
|     decoder.bert.encoder.layer.2.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.2.crossattention.self.key.weight      |        50.02%        |
|      decoder.bert.encoder.layer.2.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.2.crossattention.self.value.weight     |        50.08%        |
|     decoder.bert.encoder.layer.2.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.2.crossattention.output.dense.weight    |        49.97%        |
|    decoder.bert.encoder.layer.2.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.2.intermediate.dense.weight        |        50.77%        |
|         decoder.bert.encoder.layer.2.intermediate.dense.bias         |        97.04%        |
|           decoder.bert.encoder.layer.2.output.dense.weight           |        50.68%        |
|            decoder.bert.encoder.layer.2.output.dense.bias            |        56.51%        |
|         decoder.bert.encoder.layer.2.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.2.output.LayerNorm.bias          |        70.96%        |
|       decoder.bert.encoder.layer.3.attention.self.query.weight       |        50.78%        |
|        decoder.bert.encoder.layer.3.attention.self.query.bias        |        63.93%        |
|        decoder.bert.encoder.layer.3.attention.self.key.weight        |        51.08%        |
|         decoder.bert.encoder.layer.3.attention.self.key.bias         |        53.12%        |
|       decoder.bert.encoder.layer.3.attention.self.value.weight       |        50.28%        |
|        decoder.bert.encoder.layer.3.attention.self.value.bias        |        49.87%        |
|      decoder.bert.encoder.layer.3.attention.output.dense.weight      |        50.11%        |
|       decoder.bert.encoder.layer.3.attention.output.dense.bias       |        56.77%        |
|    decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias     |        74.74%        |
|    decoder.bert.encoder.layer.3.crossattention.self.query.weight     |        50.05%        |
|     decoder.bert.encoder.layer.3.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.3.crossattention.self.key.weight      |        50.0%         |
|      decoder.bert.encoder.layer.3.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.3.crossattention.self.value.weight     |        50.09%        |
|     decoder.bert.encoder.layer.3.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.3.crossattention.output.dense.weight    |        49.92%        |
|    decoder.bert.encoder.layer.3.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.3.intermediate.dense.weight        |        50.97%        |
|         decoder.bert.encoder.layer.3.intermediate.dense.bias         |        95.67%        |
|           decoder.bert.encoder.layer.3.output.dense.weight           |        50.7%         |
|            decoder.bert.encoder.layer.3.output.dense.bias            |        54.04%        |
|         decoder.bert.encoder.layer.3.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.3.output.LayerNorm.bias          |        76.17%        |
|       decoder.bert.encoder.layer.4.attention.self.query.weight       |        51.01%        |
|        decoder.bert.encoder.layer.4.attention.self.query.bias        |        69.27%        |
|        decoder.bert.encoder.layer.4.attention.self.key.weight        |        50.9%         |
|         decoder.bert.encoder.layer.4.attention.self.key.bias         |        48.83%        |
|       decoder.bert.encoder.layer.4.attention.self.value.weight       |        50.33%        |
|        decoder.bert.encoder.layer.4.attention.self.value.bias        |        50.91%        |
|      decoder.bert.encoder.layer.4.attention.output.dense.weight      |        50.23%        |
|       decoder.bert.encoder.layer.4.attention.output.dense.bias       |        52.34%        |
|    decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias     |        70.57%        |
|    decoder.bert.encoder.layer.4.crossattention.self.query.weight     |        49.99%        |
|     decoder.bert.encoder.layer.4.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.4.crossattention.self.key.weight      |        49.94%        |
|      decoder.bert.encoder.layer.4.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.4.crossattention.self.value.weight     |        49.94%        |
|     decoder.bert.encoder.layer.4.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.4.crossattention.output.dense.weight    |        50.05%        |
|    decoder.bert.encoder.layer.4.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.4.intermediate.dense.weight        |        50.92%        |
|         decoder.bert.encoder.layer.4.intermediate.dense.bias         |        96.09%        |
|           decoder.bert.encoder.layer.4.output.dense.weight           |        50.84%        |
|            decoder.bert.encoder.layer.4.output.dense.bias            |        51.17%        |
|         decoder.bert.encoder.layer.4.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.4.output.LayerNorm.bias          |        75.78%        |
|       decoder.bert.encoder.layer.5.attention.self.query.weight       |        51.17%        |
|        decoder.bert.encoder.layer.5.attention.self.query.bias        |        64.32%        |
|        decoder.bert.encoder.layer.5.attention.self.key.weight        |        51.28%        |
|         decoder.bert.encoder.layer.5.attention.self.key.bias         |        49.09%        |
|       decoder.bert.encoder.layer.5.attention.self.value.weight       |        50.31%        |
|        decoder.bert.encoder.layer.5.attention.self.value.bias        |        47.92%        |
|      decoder.bert.encoder.layer.5.attention.output.dense.weight      |        50.28%        |
|       decoder.bert.encoder.layer.5.attention.output.dense.bias       |        50.52%        |
|    decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias     |        71.35%        |
|    decoder.bert.encoder.layer.5.crossattention.self.query.weight     |        50.02%        |
|     decoder.bert.encoder.layer.5.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.5.crossattention.self.key.weight      |        50.11%        |
|      decoder.bert.encoder.layer.5.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.5.crossattention.self.value.weight     |        49.92%        |
|     decoder.bert.encoder.layer.5.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.5.crossattention.output.dense.weight    |        49.99%        |
|    decoder.bert.encoder.layer.5.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.5.intermediate.dense.weight        |        50.88%        |
|         decoder.bert.encoder.layer.5.intermediate.dense.bias         |        95.31%        |
|           decoder.bert.encoder.layer.5.output.dense.weight           |        50.81%        |
|            decoder.bert.encoder.layer.5.output.dense.bias            |        51.04%        |
|         decoder.bert.encoder.layer.5.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.5.output.LayerNorm.bias          |        72.66%        |
|       decoder.bert.encoder.layer.6.attention.self.query.weight       |        51.02%        |
|        decoder.bert.encoder.layer.6.attention.self.query.bias        |        66.02%        |
|        decoder.bert.encoder.layer.6.attention.self.key.weight        |        51.03%        |
|         decoder.bert.encoder.layer.6.attention.self.key.bias         |        51.56%        |
|       decoder.bert.encoder.layer.6.attention.self.value.weight       |        50.28%        |
|        decoder.bert.encoder.layer.6.attention.self.value.bias        |        50.0%         |
|      decoder.bert.encoder.layer.6.attention.output.dense.weight      |        50.24%        |
|       decoder.bert.encoder.layer.6.attention.output.dense.bias       |        51.69%        |
|    decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias     |        68.62%        |
|    decoder.bert.encoder.layer.6.crossattention.self.query.weight     |        49.97%        |
|     decoder.bert.encoder.layer.6.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.6.crossattention.self.key.weight      |        49.92%        |
|      decoder.bert.encoder.layer.6.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.6.crossattention.self.value.weight     |        50.02%        |
|     decoder.bert.encoder.layer.6.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.6.crossattention.output.dense.weight    |        49.98%        |
|    decoder.bert.encoder.layer.6.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.6.intermediate.dense.weight        |        50.88%        |
|         decoder.bert.encoder.layer.6.intermediate.dense.bias         |        95.08%        |
|           decoder.bert.encoder.layer.6.output.dense.weight           |        50.68%        |
|            decoder.bert.encoder.layer.6.output.dense.bias            |        55.73%        |
|         decoder.bert.encoder.layer.6.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.6.output.LayerNorm.bias          |        74.35%        |
|       decoder.bert.encoder.layer.7.attention.self.query.weight       |        51.05%        |
|        decoder.bert.encoder.layer.7.attention.self.query.bias        |        65.36%        |
|        decoder.bert.encoder.layer.7.attention.self.key.weight        |        51.17%        |
|         decoder.bert.encoder.layer.7.attention.self.key.bias         |        49.35%        |
|       decoder.bert.encoder.layer.7.attention.self.value.weight       |        50.06%        |
|        decoder.bert.encoder.layer.7.attention.self.value.bias        |        52.34%        |
|      decoder.bert.encoder.layer.7.attention.output.dense.weight      |        50.2%         |
|       decoder.bert.encoder.layer.7.attention.output.dense.bias       |        51.95%        |
|    decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias     |        73.44%        |
|    decoder.bert.encoder.layer.7.crossattention.self.query.weight     |        49.95%        |
|     decoder.bert.encoder.layer.7.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.7.crossattention.self.key.weight      |        49.95%        |
|      decoder.bert.encoder.layer.7.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.7.crossattention.self.value.weight     |        50.15%        |
|     decoder.bert.encoder.layer.7.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.7.crossattention.output.dense.weight    |        49.81%        |
|    decoder.bert.encoder.layer.7.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.7.intermediate.dense.weight        |        50.35%        |
|         decoder.bert.encoder.layer.7.intermediate.dense.bias         |        96.61%        |
|           decoder.bert.encoder.layer.7.output.dense.weight           |        50.55%        |
|            decoder.bert.encoder.layer.7.output.dense.bias            |        58.72%        |
|         decoder.bert.encoder.layer.7.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.7.output.LayerNorm.bias          |        75.0%         |
|       decoder.bert.encoder.layer.8.attention.self.query.weight       |        51.16%        |
|        decoder.bert.encoder.layer.8.attention.self.query.bias        |        71.61%        |
|        decoder.bert.encoder.layer.8.attention.self.key.weight        |        51.34%        |
|         decoder.bert.encoder.layer.8.attention.self.key.bias         |        48.18%        |
|       decoder.bert.encoder.layer.8.attention.self.value.weight       |        50.34%        |
|        decoder.bert.encoder.layer.8.attention.self.value.bias        |        54.17%        |
|      decoder.bert.encoder.layer.8.attention.output.dense.weight      |        50.24%        |
|       decoder.bert.encoder.layer.8.attention.output.dense.bias       |        50.26%        |
|    decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias     |        74.35%        |
|    decoder.bert.encoder.layer.8.crossattention.self.query.weight     |        49.95%        |
|     decoder.bert.encoder.layer.8.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.8.crossattention.self.key.weight      |        49.95%        |
|      decoder.bert.encoder.layer.8.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.8.crossattention.self.value.weight     |        49.87%        |
|     decoder.bert.encoder.layer.8.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.8.crossattention.output.dense.weight    |        49.96%        |
|    decoder.bert.encoder.layer.8.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.8.intermediate.dense.weight        |        50.25%        |
|         decoder.bert.encoder.layer.8.intermediate.dense.bias         |        97.4%         |
|           decoder.bert.encoder.layer.8.output.dense.weight           |        50.46%        |
|            decoder.bert.encoder.layer.8.output.dense.bias            |        59.24%        |
|         decoder.bert.encoder.layer.8.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.8.output.LayerNorm.bias          |        75.52%        |
|       decoder.bert.encoder.layer.9.attention.self.query.weight       |        51.58%        |
|        decoder.bert.encoder.layer.9.attention.self.query.bias        |        73.96%        |
|        decoder.bert.encoder.layer.9.attention.self.key.weight        |        51.43%        |
|         decoder.bert.encoder.layer.9.attention.self.key.bias         |        48.44%        |
|       decoder.bert.encoder.layer.9.attention.self.value.weight       |        50.13%        |
|        decoder.bert.encoder.layer.9.attention.self.value.bias        |        51.69%        |
|      decoder.bert.encoder.layer.9.attention.output.dense.weight      |        50.22%        |
|       decoder.bert.encoder.layer.9.attention.output.dense.bias       |        54.04%        |
|    decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight    |        100.0%        |
|     decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias     |        73.7%         |
|    decoder.bert.encoder.layer.9.crossattention.self.query.weight     |        50.03%        |
|     decoder.bert.encoder.layer.9.crossattention.self.query.bias      |         0.0%         |
|     decoder.bert.encoder.layer.9.crossattention.self.key.weight      |        49.93%        |
|      decoder.bert.encoder.layer.9.crossattention.self.key.bias       |         0.0%         |
|    decoder.bert.encoder.layer.9.crossattention.self.value.weight     |        49.87%        |
|     decoder.bert.encoder.layer.9.crossattention.self.value.bias      |         0.0%         |
|   decoder.bert.encoder.layer.9.crossattention.output.dense.weight    |        49.99%        |
|    decoder.bert.encoder.layer.9.crossattention.output.dense.bias     |         0.0%         |
| decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight  |        100.0%        |
|  decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias   |         0.0%         |
|        decoder.bert.encoder.layer.9.intermediate.dense.weight        |        50.16%        |
|         decoder.bert.encoder.layer.9.intermediate.dense.bias         |        98.27%        |
|           decoder.bert.encoder.layer.9.output.dense.weight           |        50.56%        |
|            decoder.bert.encoder.layer.9.output.dense.bias            |        59.11%        |
|         decoder.bert.encoder.layer.9.output.LayerNorm.weight         |        100.0%        |
|          decoder.bert.encoder.layer.9.output.LayerNorm.bias          |        76.04%        |
|      decoder.bert.encoder.layer.10.attention.self.query.weight       |        51.4%         |
|       decoder.bert.encoder.layer.10.attention.self.query.bias        |        69.14%        |
|       decoder.bert.encoder.layer.10.attention.self.key.weight        |        51.39%        |
|        decoder.bert.encoder.layer.10.attention.self.key.bias         |        49.35%        |
|      decoder.bert.encoder.layer.10.attention.self.value.weight       |        50.45%        |
|       decoder.bert.encoder.layer.10.attention.self.value.bias        |        50.91%        |
|     decoder.bert.encoder.layer.10.attention.output.dense.weight      |        50.17%        |
|      decoder.bert.encoder.layer.10.attention.output.dense.bias       |        54.56%        |
|   decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight    |        100.0%        |
|    decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias     |        66.02%        |
|    decoder.bert.encoder.layer.10.crossattention.self.query.weight    |        49.95%        |
|     decoder.bert.encoder.layer.10.crossattention.self.query.bias     |         0.0%         |
|     decoder.bert.encoder.layer.10.crossattention.self.key.weight     |        50.06%        |
|      decoder.bert.encoder.layer.10.crossattention.self.key.bias      |         0.0%         |
|    decoder.bert.encoder.layer.10.crossattention.self.value.weight    |        49.98%        |
|     decoder.bert.encoder.layer.10.crossattention.self.value.bias     |         0.0%         |
|   decoder.bert.encoder.layer.10.crossattention.output.dense.weight   |        50.01%        |
|    decoder.bert.encoder.layer.10.crossattention.output.dense.bias    |         0.0%         |
| decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight |        100.0%        |
|  decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias  |         0.0%         |
|       decoder.bert.encoder.layer.10.intermediate.dense.weight        |        50.47%        |
|        decoder.bert.encoder.layer.10.intermediate.dense.bias         |        99.06%        |
|          decoder.bert.encoder.layer.10.output.dense.weight           |        50.4%         |
|           decoder.bert.encoder.layer.10.output.dense.bias            |        65.23%        |
|        decoder.bert.encoder.layer.10.output.LayerNorm.weight         |        100.0%        |
|         decoder.bert.encoder.layer.10.output.LayerNorm.bias          |        85.94%        |
|      decoder.bert.encoder.layer.11.attention.self.query.weight       |        51.49%        |
|       decoder.bert.encoder.layer.11.attention.self.query.bias        |        79.43%        |
|       decoder.bert.encoder.layer.11.attention.self.key.weight        |        51.01%        |
|        decoder.bert.encoder.layer.11.attention.self.key.bias         |        51.43%        |
|      decoder.bert.encoder.layer.11.attention.self.value.weight       |        50.66%        |
|       decoder.bert.encoder.layer.11.attention.self.value.bias        |        48.44%        |
|     decoder.bert.encoder.layer.11.attention.output.dense.weight      |        50.37%        |
|      decoder.bert.encoder.layer.11.attention.output.dense.bias       |        50.26%        |
|   decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight    |        100.0%        |
|    decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias     |        72.14%        |
|    decoder.bert.encoder.layer.11.crossattention.self.query.weight    |        49.95%        |
|     decoder.bert.encoder.layer.11.crossattention.self.query.bias     |         0.0%         |
|     decoder.bert.encoder.layer.11.crossattention.self.key.weight     |        49.99%        |
|      decoder.bert.encoder.layer.11.crossattention.self.key.bias      |         0.0%         |
|    decoder.bert.encoder.layer.11.crossattention.self.value.weight    |        49.89%        |
|     decoder.bert.encoder.layer.11.crossattention.self.value.bias     |         0.0%         |
|   decoder.bert.encoder.layer.11.crossattention.output.dense.weight   |        50.1%         |
|    decoder.bert.encoder.layer.11.crossattention.output.dense.bias    |         0.0%         |
| decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight |        100.0%        |
|  decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias  |         0.0%         |
|       decoder.bert.encoder.layer.11.intermediate.dense.weight        |        50.12%        |
|        decoder.bert.encoder.layer.11.intermediate.dense.bias         |        97.33%        |
|          decoder.bert.encoder.layer.11.output.dense.weight           |        50.32%        |
|           decoder.bert.encoder.layer.11.output.dense.bias            |        51.69%        |
|        decoder.bert.encoder.layer.11.output.LayerNorm.weight         |        100.0%        |
|         decoder.bert.encoder.layer.11.output.LayerNorm.bias          |        68.62%        |
|                     decoder.cls.predictions.bias                     |        97.12%        |
|            decoder.cls.predictions.transform.dense.weight            |        52.14%        |
|             decoder.cls.predictions.transform.dense.bias             |        8.72%         |
|          decoder.cls.predictions.transform.LayerNorm.weight          |        99.74%        |
|           decoder.cls.predictions.transform.LayerNorm.bias           |        91.93%        |
+----------------------------------------------------------------------+----------------------+

# T5
What fraction of parameters >> 0 overall? Percent of model parameters > 0.1 is 90.82% (also see chart in t5_histogram.png)
What fraction of parameters >> 0 by layer? See table:
+----------------------------------------------------------------------+----------------------+
|                                Layers                                | Percent Params > 0.1 |
+----------------------------------------------------------------------+----------------------+
|                            shared.weight                             |        99.82%        |
|            encoder.block.0.layer.0.SelfAttention.q.weight            |        54.48%        |
|            encoder.block.0.layer.0.SelfAttention.k.weight            |        90.64%        |
|            encoder.block.0.layer.0.SelfAttention.v.weight            |        90.72%        |
|            encoder.block.0.layer.0.SelfAttention.o.weight            |        92.2%         |
| encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight |        97.66%        |
|              encoder.block.0.layer.0.layer_norm.weight               |        32.62%        |
|           encoder.block.0.layer.1.DenseReluDense.wi.weight           |        92.92%        |
|           encoder.block.0.layer.1.DenseReluDense.wo.weight           |        84.94%        |
|              encoder.block.0.layer.1.layer_norm.weight               |        99.61%        |
|            encoder.block.1.layer.0.SelfAttention.q.weight            |        54.71%        |
|            encoder.block.1.layer.0.SelfAttention.k.weight            |        90.97%        |
|            encoder.block.1.layer.0.SelfAttention.v.weight            |        92.86%        |
|            encoder.block.1.layer.0.SelfAttention.o.weight            |        93.47%        |
|              encoder.block.1.layer.0.layer_norm.weight               |        46.09%        |
|           encoder.block.1.layer.1.DenseReluDense.wi.weight           |        94.15%        |
|           encoder.block.1.layer.1.DenseReluDense.wo.weight           |        86.65%        |
|              encoder.block.1.layer.1.layer_norm.weight               |        100.0%        |
|            encoder.block.2.layer.0.SelfAttention.q.weight            |        51.45%        |
|            encoder.block.2.layer.0.SelfAttention.k.weight            |        89.18%        |
|            encoder.block.2.layer.0.SelfAttention.v.weight            |        93.23%        |
|            encoder.block.2.layer.0.SelfAttention.o.weight            |        93.53%        |
|              encoder.block.2.layer.0.layer_norm.weight               |        95.12%        |
|           encoder.block.2.layer.1.DenseReluDense.wi.weight           |        94.47%        |
|           encoder.block.2.layer.1.DenseReluDense.wo.weight           |        87.79%        |
|              encoder.block.2.layer.1.layer_norm.weight               |        100.0%        |
|            encoder.block.3.layer.0.SelfAttention.q.weight            |        53.43%        |
|            encoder.block.3.layer.0.SelfAttention.k.weight            |        90.78%        |
|            encoder.block.3.layer.0.SelfAttention.v.weight            |        93.85%        |
|            encoder.block.3.layer.0.SelfAttention.o.weight            |        94.24%        |
|              encoder.block.3.layer.0.layer_norm.weight               |        91.02%        |
|           encoder.block.3.layer.1.DenseReluDense.wi.weight           |        94.49%        |
|           encoder.block.3.layer.1.DenseReluDense.wo.weight           |        88.13%        |
|              encoder.block.3.layer.1.layer_norm.weight               |        100.0%        |
|            encoder.block.4.layer.0.SelfAttention.q.weight            |        53.5%         |
|            encoder.block.4.layer.0.SelfAttention.k.weight            |        90.83%        |
|            encoder.block.4.layer.0.SelfAttention.v.weight            |        94.49%        |
|            encoder.block.4.layer.0.SelfAttention.o.weight            |        94.89%        |
|              encoder.block.4.layer.0.layer_norm.weight               |        89.45%        |
|           encoder.block.4.layer.1.DenseReluDense.wi.weight           |        94.79%        |
|           encoder.block.4.layer.1.DenseReluDense.wo.weight           |        88.56%        |
|              encoder.block.4.layer.1.layer_norm.weight               |        100.0%        |
|            encoder.block.5.layer.0.SelfAttention.q.weight            |        53.16%        |
|            encoder.block.5.layer.0.SelfAttention.k.weight            |        90.41%        |
|            encoder.block.5.layer.0.SelfAttention.v.weight            |        95.13%        |
|            encoder.block.5.layer.0.SelfAttention.o.weight            |        95.41%        |
|              encoder.block.5.layer.0.layer_norm.weight               |        86.91%        |
|           encoder.block.5.layer.1.DenseReluDense.wi.weight           |        94.59%        |
|           encoder.block.5.layer.1.DenseReluDense.wo.weight           |        88.78%        |
|              encoder.block.5.layer.1.layer_norm.weight               |        100.0%        |
|                   encoder.final_layer_norm.weight                    |        94.73%        |
|            decoder.block.0.layer.0.SelfAttention.q.weight            |        57.24%        |
|            decoder.block.0.layer.0.SelfAttention.k.weight            |        92.35%        |
|            decoder.block.0.layer.0.SelfAttention.v.weight            |        91.58%        |
|            decoder.block.0.layer.0.SelfAttention.o.weight            |        93.61%        |
| decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight |        98.83%        |
|              decoder.block.0.layer.0.layer_norm.weight               |        27.15%        |
|           decoder.block.0.layer.1.EncDecAttention.q.weight           |        54.87%        |
|           decoder.block.0.layer.1.EncDecAttention.k.weight           |        88.9%         |
|           decoder.block.0.layer.1.EncDecAttention.v.weight           |        90.65%        |
|           decoder.block.0.layer.1.EncDecAttention.o.weight           |        92.53%        |
|              decoder.block.0.layer.1.layer_norm.weight               |        14.26%        |
|           decoder.block.0.layer.2.DenseReluDense.wi.weight           |        93.03%        |
|           decoder.block.0.layer.2.DenseReluDense.wo.weight           |        86.02%        |
|              decoder.block.0.layer.2.layer_norm.weight               |        100.0%        |
|            decoder.block.1.layer.0.SelfAttention.q.weight            |        53.79%        |
|            decoder.block.1.layer.0.SelfAttention.k.weight            |        90.04%        |
|            decoder.block.1.layer.0.SelfAttention.v.weight            |        94.03%        |
|            decoder.block.1.layer.0.SelfAttention.o.weight            |        94.6%         |
|              decoder.block.1.layer.0.layer_norm.weight               |        83.4%         |
|           decoder.block.1.layer.1.EncDecAttention.q.weight           |        58.24%        |
|           decoder.block.1.layer.1.EncDecAttention.k.weight           |        87.65%        |
|           decoder.block.1.layer.1.EncDecAttention.v.weight           |        92.9%         |
|           decoder.block.1.layer.1.EncDecAttention.o.weight           |        93.15%        |
|              decoder.block.1.layer.1.layer_norm.weight               |        46.29%        |
|           decoder.block.1.layer.2.DenseReluDense.wi.weight           |        93.88%        |
|           decoder.block.1.layer.2.DenseReluDense.wo.weight           |        86.96%        |
|              decoder.block.1.layer.2.layer_norm.weight               |        100.0%        |
|            decoder.block.2.layer.0.SelfAttention.q.weight            |        52.14%        |
|            decoder.block.2.layer.0.SelfAttention.k.weight            |        89.65%        |
|            decoder.block.2.layer.0.SelfAttention.v.weight            |        95.42%        |
|            decoder.block.2.layer.0.SelfAttention.o.weight            |        95.49%        |
|              decoder.block.2.layer.0.layer_norm.weight               |        87.89%        |
|           decoder.block.2.layer.1.EncDecAttention.q.weight           |        56.91%        |
|           decoder.block.2.layer.1.EncDecAttention.k.weight           |        88.36%        |
|           decoder.block.2.layer.1.EncDecAttention.v.weight           |        94.02%        |
|           decoder.block.2.layer.1.EncDecAttention.o.weight           |        93.92%        |
|              decoder.block.2.layer.1.layer_norm.weight               |        23.05%        |
|           decoder.block.2.layer.2.DenseReluDense.wi.weight           |        94.12%        |
|           decoder.block.2.layer.2.DenseReluDense.wo.weight           |        87.69%        |
|              decoder.block.2.layer.2.layer_norm.weight               |        100.0%        |
|            decoder.block.3.layer.0.SelfAttention.q.weight            |        51.71%        |
|            decoder.block.3.layer.0.SelfAttention.k.weight            |        89.88%        |
|            decoder.block.3.layer.0.SelfAttention.v.weight            |        95.56%        |
|            decoder.block.3.layer.0.SelfAttention.o.weight            |        96.22%        |
|              decoder.block.3.layer.0.layer_norm.weight               |        94.92%        |
|           decoder.block.3.layer.1.EncDecAttention.q.weight           |        51.25%        |
|           decoder.block.3.layer.1.EncDecAttention.k.weight           |        88.41%        |
|           decoder.block.3.layer.1.EncDecAttention.v.weight           |        94.8%         |
|           decoder.block.3.layer.1.EncDecAttention.o.weight           |        95.02%        |
|              decoder.block.3.layer.1.layer_norm.weight               |        82.42%        |
|           decoder.block.3.layer.2.DenseReluDense.wi.weight           |        93.63%        |
|           decoder.block.3.layer.2.DenseReluDense.wo.weight           |        87.92%        |
|              decoder.block.3.layer.2.layer_norm.weight               |        100.0%        |
|            decoder.block.4.layer.0.SelfAttention.q.weight            |        51.15%        |
|            decoder.block.4.layer.0.SelfAttention.k.weight            |        90.17%        |
|            decoder.block.4.layer.0.SelfAttention.v.weight            |        95.17%        |
|            decoder.block.4.layer.0.SelfAttention.o.weight            |        97.34%        |
|              decoder.block.4.layer.0.layer_norm.weight               |        97.66%        |
|           decoder.block.4.layer.1.EncDecAttention.q.weight           |        53.95%        |
|           decoder.block.4.layer.1.EncDecAttention.k.weight           |        90.33%        |
|           decoder.block.4.layer.1.EncDecAttention.v.weight           |        95.58%        |
|           decoder.block.4.layer.1.EncDecAttention.o.weight           |        95.93%        |
|              decoder.block.4.layer.1.layer_norm.weight               |        6.25%         |
|           decoder.block.4.layer.2.DenseReluDense.wi.weight           |        93.81%        |
|           decoder.block.4.layer.2.DenseReluDense.wo.weight           |        88.38%        |
|              decoder.block.4.layer.2.layer_norm.weight               |        100.0%        |
|            decoder.block.5.layer.0.SelfAttention.q.weight            |        51.05%        |
|            decoder.block.5.layer.0.SelfAttention.k.weight            |        89.7%         |
|            decoder.block.5.layer.0.SelfAttention.v.weight            |        95.58%        |
|            decoder.block.5.layer.0.SelfAttention.o.weight            |        96.57%        |
|              decoder.block.5.layer.0.layer_norm.weight               |        99.41%        |
|           decoder.block.5.layer.1.EncDecAttention.q.weight           |        51.09%        |
|           decoder.block.5.layer.1.EncDecAttention.k.weight           |        88.23%        |
|           decoder.block.5.layer.1.EncDecAttention.v.weight           |        96.4%         |
|           decoder.block.5.layer.1.EncDecAttention.o.weight           |        96.31%        |
|              decoder.block.5.layer.1.layer_norm.weight               |        97.46%        |
|           decoder.block.5.layer.2.DenseReluDense.wi.weight           |        94.59%        |
|           decoder.block.5.layer.2.DenseReluDense.wo.weight           |        88.7%         |
|              decoder.block.5.layer.2.layer_norm.weight               |        100.0%        |
|                   decoder.final_layer_norm.weight                    |        98.24%        |
+----------------------------------------------------------------------+----------------------+
